{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b732e7e",
   "metadata": {},
   "source": [
    "# Instalar dependencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3f9063f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in c:\\users\\estudiante\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.1.0)\n",
      "Requirement already satisfied: dotenv in c:\\users\\estudiante\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (0.9.9)\n",
      "Requirement already satisfied: gradio in c:\\users\\estudiante\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (5.48.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\estudiante\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from openai) (4.11.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\estudiante\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\estudiante\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\estudiante\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from openai) (0.11.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\estudiante\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from openai) (2.11.9)\n",
      "Requirement already satisfied: sniffio in c:\\users\\estudiante\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\estudiante\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\estudiante\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from openai) (4.15.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\estudiante\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in c:\\users\\estudiante\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\estudiante\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\estudiante\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\estudiante\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\estudiante\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\estudiante\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.4.2)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\estudiante\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from dotenv) (1.1.1)\n",
      "Requirement already satisfied: aiofiles<25.0,>=22.0 in c:\\users\\estudiante\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from gradio) (24.1.0)\n",
      "Requirement already satisfied: audioop-lts<1.0 in c:\\users\\estudiante\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from gradio) (0.2.2)\n",
      "Requirement already satisfied: brotli>=1.1.0 in c:\\users\\estudiante\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from gradio) (1.1.0)\n",
      "Requirement already satisfied: fastapi<1.0,>=0.115.2 in c:\\users\\estudiante\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from gradio) (0.118.0)\n",
      "Requirement already satisfied: ffmpy in c:\\users\\estudiante\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from gradio) (0.6.1)\n",
      "Requirement already satisfied: gradio-client==1.13.3 in c:\\users\\estudiante\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from gradio) (1.13.3)\n",
      "Requirement already satisfied: groovy~=0.1 in c:\\users\\estudiante\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from gradio) (0.1.2)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=0.33.5 in c:\\users\\estudiante\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from gradio) (0.35.3)\n",
      "Requirement already satisfied: jinja2<4.0 in c:\\users\\estudiante\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from gradio) (3.1.6)\n",
      "Requirement already satisfied: markupsafe<4.0,>=2.0 in c:\\users\\estudiante\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from gradio) (3.0.3)\n",
      "Requirement already satisfied: numpy<3.0,>=1.0 in c:\\users\\estudiante\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from gradio) (2.3.3)\n",
      "Requirement already satisfied: orjson~=3.0 in c:\\users\\estudiante\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from gradio) (3.11.3)\n",
      "Requirement already satisfied: packaging in c:\\users\\estudiante\\appdata\\roaming\\python\\python313\\site-packages (from gradio) (25.0)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in c:\\users\\estudiante\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from gradio) (2.3.3)\n",
      "Requirement already satisfied: pillow<12.0,>=8.0 in c:\\users\\estudiante\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from gradio) (11.3.0)\n",
      "Requirement already satisfied: pydub in c:\\users\\estudiante\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from gradio) (0.25.1)\n",
      "Requirement already satisfied: python-multipart>=0.0.18 in c:\\users\\estudiante\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from gradio) (0.0.20)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in c:\\users\\estudiante\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from gradio) (6.0.3)\n",
      "Requirement already satisfied: ruff>=0.9.3 in c:\\users\\estudiante\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from gradio) (0.13.3)\n",
      "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in c:\\users\\estudiante\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from gradio) (0.1.6)\n",
      "Requirement already satisfied: semantic-version~=2.0 in c:\\users\\estudiante\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from gradio) (2.10.0)\n",
      "Requirement already satisfied: starlette<1.0,>=0.40.0 in c:\\users\\estudiante\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from gradio) (0.48.0)\n",
      "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in c:\\users\\estudiante\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from gradio) (0.13.3)\n",
      "Requirement already satisfied: typer<1.0,>=0.12 in c:\\users\\estudiante\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from gradio) (0.19.2)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in c:\\users\\estudiante\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from gradio) (0.37.0)\n",
      "Requirement already satisfied: fsspec in c:\\users\\estudiante\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from gradio-client==1.13.3->gradio) (2025.9.0)\n",
      "Requirement already satisfied: websockets<16.0,>=13.0 in c:\\users\\estudiante\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from gradio-client==1.13.3->gradio) (15.0.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\estudiante\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (3.19.1)\n",
      "Requirement already satisfied: requests in c:\\users\\estudiante\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (2.32.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\estudiante\\appdata\\roaming\\python\\python313\\site-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\estudiante\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\estudiante\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\estudiante\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (8.3.0)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\estudiante\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\estudiante\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (14.1.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\estudiante\\appdata\\roaming\\python\\python313\\site-packages (from click>=8.0.0->typer<1.0,>=0.12->gradio) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\estudiante\\appdata\\roaming\\python\\python313\\site-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\estudiante\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\estudiante\\appdata\\roaming\\python\\python313\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\estudiante\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\estudiante\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->huggingface-hub<2.0,>=0.33.5->gradio) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\estudiante\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->huggingface-hub<2.0,>=0.33.5->gradio) (2.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install openai dotenv gradio "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2d56ed",
   "metadata": {},
   "source": [
    "# Importar librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e63fc81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Estudiante\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from openai import OpenAI\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27fc9fce",
   "metadata": {},
   "source": [
    "# Definir las variables de las API KEYS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e549807",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)\n",
    "open_router_api_key = os.getenv('OPEN_ROUTER_API_KEY')\n",
    "gemini_api_key = os.getenv('GEMINI_API_KEY')\n",
    "groq_api_key = os.getenv('GROQ_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7008d4fa",
   "metadata": {},
   "source": [
    "# Conectar los distintos modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5934f57d",
   "metadata": {},
   "source": [
    "## Google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a1bf513",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'**IA** significa **Inteligencia Artificial**.\\n\\nEn términos sencillos, la Inteligencia Artificial se refiere a la capacidad de las máquinas o sistemas informáticos para **realizar tareas que normalmente requieren inteligencia humana**. Esto incluye cosas como:\\n\\n*   **Aprender** de la experiencia (es decir, de los datos).\\n*   **Resolver problemas**.\\n*   **Comprender** el lenguaje humano (hablado o escrito).\\n*   **Reconocer** patrones, objetos o rostros en imágenes y videos.\\n*   **Tomar decisiones** basadas en la información.\\n*   **Adaptarse** a nuevas situaciones.\\n\\n**¿Cómo funciona?**\\nLa IA se basa en algoritmos complejos y modelos matemáticos que procesan grandes cantidades de datos. Un campo clave dentro de la IA es el **aprendizaje automático (Machine Learning)**, donde los sistemas aprenden de los datos sin ser programados explícitamente para cada tarea. Dentro del aprendizaje automático, está el **aprendizaje profundo (Deep Learning)**, que utiliza redes neuronales artificiales inspiradas en el cerebro humano para reconocer patrones muy complejos.\\n\\n**Tipos de IA:**\\nEs importante notar que la mayoría de la IA que vemos hoy es lo que se llama \"IA débil\" o \"IA estrecha\" (Artificial Narrow Intelligence - ANI). Esto significa que está diseñada para una tarea específica y destacarse en ella (por ejemplo, recomendar videos, traducir idiomas, jugar al ajedrez). La \"IA fuerte\" o \"IA general\" (Artificial General Intelligence - AGI), que tendría una inteligencia comparable a la humana en un amplio rango de tareas, es algo que aún está en desarrollo o es teórico.\\n\\n**Ejemplos comunes de IA en acción:**\\n\\n*   **Asistentes de voz:** Siri, Alexa, Google Assistant.\\n*   **Sistemas de recomendación:** Lo que te sugiere Netflix, Amazon o Spotify.\\n*   **Coches autónomos:** Vehículos que pueden conducirse solos.\\n*   **Filtros de spam** en el correo electrónico.\\n*   **Diagnóstico médico asistido por computadora:** Ayuda a los doctores a detectar enfermedades.\\n*   **Reconocimiento facial** para desbloquear tu teléfono.\\n*   **Herramientas de IA generativa:** Como ChatGPT (que genera texto), DALL-E o Midjourney (que crean imágenes a partir de descripciones).\\n\\nEn resumen, la IA es una rama de la informática que busca dotar a las máquinas de capacidades cognitivas similares a las humanas, permitiéndoles percibir, razonar, aprender y actuar de manera \"inteligente\". Está transformando rápidamente muchos aspectos de nuestra vida y trabajo.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#gemini = OpenAI(api_key=gemini_api_key, base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\")\n",
    "#model_name = \"gemini-2.5-flash\"\n",
    "\n",
    "gemini_model = dict(model=OpenAI(api_key=gemini_api_key, base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\"), model_name=\"gemini-2.5-flash\")\n",
    "\n",
    "response = gemini_model[\"model\"].chat.completions.create(model=gemini_model[\"model_name\"], messages=[\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"Que es AI\"\n",
    "    }\n",
    "  ])\n",
    "answer = response.choices[0].message.content\n",
    "answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9f01a9",
   "metadata": {},
   "source": [
    "## OpenRouterAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "670cfb37",
   "metadata": {},
   "outputs": [
    {
     "ename": "AuthenticationError",
     "evalue": "Error code: 401 - {'error': {'message': 'No auth credentials found', 'code': 401}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAuthenticationError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m#open_router_ai = OpenAI(\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m#  base_url=\"https://openrouter.ai/api/v1\",\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m#  api_key=open_router_api_key,\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m#)\u001b[39;00m\n\u001b[32m      6\u001b[39m open_router_model = \u001b[38;5;28mdict\u001b[39m(model=OpenAI(\n\u001b[32m      7\u001b[39m   base_url=\u001b[33m\"\u001b[39m\u001b[33mhttps://openrouter.ai/api/v1\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      8\u001b[39m   api_key=open_router_api_key,\n\u001b[32m      9\u001b[39m ), \n\u001b[32m     10\u001b[39m model_name=\u001b[33m\"\u001b[39m\u001b[33mdeepseek/deepseek-r1-0528\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m completion = \u001b[43mopen_router_model\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mchat\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompletions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m  \u001b[49m\u001b[38;5;66;43;03m#extra_headers={\u001b[39;49;00m\n\u001b[32m     14\u001b[39m \u001b[43m  \u001b[49m\u001b[38;5;66;43;03m#  \"HTTP-Referer\": \"MI PAGINA o APP\", \u001b[39;49;00m\n\u001b[32m     15\u001b[39m \u001b[43m  \u001b[49m\u001b[38;5;66;43;03m#  \"X-Title\": \"ANDY CODE\",\u001b[39;49;00m\n\u001b[32m     16\u001b[39m \u001b[43m  \u001b[49m\u001b[38;5;66;43;03m#},\u001b[39;49;00m\n\u001b[32m     17\u001b[39m \u001b[43m  \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mopen_router_model\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m  \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m    \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m      \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrole\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m      \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcontent\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mQue es AI\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m     22\u001b[39m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[43m  \u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[38;5;28mprint\u001b[39m(completion.choices[\u001b[32m0\u001b[39m].message.content)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Estudiante\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\openai\\_utils\\_utils.py:286\u001b[39m, in \u001b[36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    284\u001b[39m             msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[32m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    285\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[32m--> \u001b[39m\u001b[32m286\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Estudiante\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py:1147\u001b[39m, in \u001b[36mCompletions.create\u001b[39m\u001b[34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, prompt_cache_key, reasoning_effort, response_format, safety_identifier, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, verbosity, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m   1101\u001b[39m \u001b[38;5;129m@required_args\u001b[39m([\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m], [\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m   1102\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m   1103\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1144\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = not_given,\n\u001b[32m   1145\u001b[39m ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[32m   1146\u001b[39m     validate_response_format(response_format)\n\u001b[32m-> \u001b[39m\u001b[32m1147\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1148\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/chat/completions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1149\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1150\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m   1151\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1152\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1153\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43maudio\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1154\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfrequency_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1155\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunction_call\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1156\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunctions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1157\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogit_bias\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1158\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1159\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_completion_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1160\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1161\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1162\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodalities\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1163\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1164\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallel_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1165\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprediction\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1166\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpresence_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1167\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprompt_cache_key\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_cache_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1168\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning_effort\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1169\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1170\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msafety_identifier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msafety_identifier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1171\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1172\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1173\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstop\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1174\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1175\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1176\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1177\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1178\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1179\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1180\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_logprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1181\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1183\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mverbosity\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbosity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1184\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweb_search_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweb_search_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1185\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1186\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsStreaming\u001b[49m\n\u001b[32m   1187\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\n\u001b[32m   1188\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsNonStreaming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1189\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1190\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1191\u001b[39m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m   1192\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1193\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1194\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1195\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1196\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Estudiante\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\openai\\_base_client.py:1259\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1245\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1246\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1247\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1254\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1255\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1256\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1257\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1258\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1259\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Estudiante\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\openai\\_base_client.py:1047\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1044\u001b[39m             err.response.read()\n\u001b[32m   1046\u001b[39m         log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1047\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1049\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1051\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mcould not resolve response (should never happen)\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mAuthenticationError\u001b[39m: Error code: 401 - {'error': {'message': 'No auth credentials found', 'code': 401}}"
     ]
    }
   ],
   "source": [
    "#open_router_ai = OpenAI(\n",
    "#  base_url=\"https://openrouter.ai/api/v1\",\n",
    "#  api_key=open_router_api_key,\n",
    "#)\n",
    "\n",
    "open_router_model = dict(model=OpenAI(\n",
    "  base_url=\"https://openrouter.ai/api/v1\",\n",
    "  api_key=open_router_api_key,\n",
    "), \n",
    "model_name=\"deepseek/deepseek-r1-0528\")\n",
    "\n",
    "completion = open_router_model[\"model\"].chat.completions.create(\n",
    "  #extra_headers={\n",
    "  #  \"HTTP-Referer\": \"MI PAGINA o APP\", \n",
    "  #  \"X-Title\": \"ANDY CODE\",\n",
    "  #},\n",
    "  model=open_router_model[\"model_name\"],\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"Que es AI\"\n",
    "    }\n",
    "  ]\n",
    ")\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f8d7ae",
   "metadata": {},
   "source": [
    "## Groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd904f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#grog_ai = OpenAI(api_key=groq_api_key, base_url=\"https://api.groq.com/openai/v1\")\n",
    "#model_name = \"llama-3.3-70b-versatile\"\n",
    "\n",
    "groq_model = dict(model=OpenAI(api_key=groq_api_key, base_url=\"https://api.groq.com/openai/v1\"), model_name=\"llama-3.3-70b-versatile\")\n",
    "\n",
    "response = groq_model[\"model\"].chat.completions.create(model=groq_model[\"model_name\"], messages=[\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"Que es AI\"\n",
    "    }\n",
    "  ])\n",
    "answer = response.choices[0].message.content\n",
    "answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02cfcfc0",
   "metadata": {},
   "source": [
    "# Crear interfaz de chat con gradio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c15b1a",
   "metadata": {},
   "source": [
    "## Funcion de chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f1a472",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "\n",
    "def obtener_valor(dict: dict, key):\n",
    "    return dict.get(key, \"Clave no encontrada\")\n",
    "\n",
    "models = dict(\n",
    "    gemini=gemini_model,\n",
    "    #open_router=open_router_model,\n",
    "    #groq=groq_model\n",
    ")\n",
    "\n",
    "chats = {}\n",
    "\n",
    "def chat(message, history, model, chats_state, current_chat_id):\n",
    "\n",
    "    # TODO: fix issue where sending a message restores full history from other chats\n",
    "\n",
    "    try:\n",
    "\n",
    "        print(f\"Modelo seleccionado: {model}\")\n",
    "        print(f\"modelo: {obtener_valor(models[model], 'model_name')}\")\n",
    "\n",
    "        # Asegurar que hay una lista para ese chat\n",
    "        if current_chat_id not in chats_state or chats_state[current_chat_id] is None:\n",
    "            chats_state[current_chat_id] = []\n",
    "\n",
    "        # Primero, guardar el history que entró (para no perder mensajes previos)\n",
    "        chats_state[current_chat_id] = history\n",
    "\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": \"Eres un asistente de IA que responde preguntas y ayuda con tareas.\"}\n",
    "        ]\n",
    "        \n",
    "        for msg in history:\n",
    "            messages.append({\"role\": msg[\"role\"], \"content\": msg[\"content\"]})\n",
    "        \n",
    "        messages.append({\"role\": \"user\", \"content\": message})\n",
    "\n",
    "\n",
    "        resp = obtener_valor(models[model], \"model\").chat.completions.create(\n",
    "            model=obtener_valor(models[model], \"model_name\"),\n",
    "            messages=messages,\n",
    "        )\n",
    "\n",
    "        # Construir nuevo historial actualizado\n",
    "        new_history = history + [\n",
    "            {\"role\": \"user\", \"content\": message},\n",
    "            {\"role\": \"assistant\", \"content\": resp}\n",
    "        ]\n",
    "\n",
    "        # Guardar nueva historia en estado\n",
    "        chats_state[current_chat_id] = new_history\n",
    "\n",
    "        return resp.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return f\"Error: {e}\"\n",
    "    \n",
    "def new_chat(chats_state: dict):\n",
    "    \"\"\"Crea un nuevo chat y lo añade al estado\"\"\"\n",
    "    chat_id = str(uuid.uuid4())[:8]  # ID único corto\n",
    "\n",
    "    while chat_id in chats_state:\n",
    "        chat_id = str(uuid.uuid4())[:8]\n",
    "\n",
    "    chats_state[chat_id] = []  # historial vacío\n",
    "\n",
    "    return chats_state, chat_id, gr.Dropdown(choices=list(chats_state.keys()), value=chat_id), []\n",
    "\n",
    "def switch_chat(chats_state, chat_id):\n",
    "    \"\"\"Cambia entre chats\"\"\"\n",
    "    return chats_state.get(chat_id, [])\n",
    "\n",
    "def save_message(chats_state, chat_id, history):\n",
    "    \"\"\"Guarda el historial en el chat actual\"\"\"\n",
    "    if chat_id:\n",
    "        chats_state[chat_id] = history\n",
    "    return chats_state\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a206937d",
   "metadata": {},
   "source": [
    "## Creacion de la interfaz del Chat con Gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e3dc87a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Estudiante\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\gradio\\components\\dropdown.py:230: UserWarning: The value passed into gr.Dropdown() is not in the list of choices. Please update the list of choices to include:  or set allow_custom_value=True.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7909\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7909/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo seleccionado: gemini\n",
      "modelo: gemini-2.5-flash\n",
      "Modelo seleccionado: gemini\n",
      "modelo: gemini-2.5-flash\n",
      "Modelo seleccionado: gemini\n",
      "modelo: gemini-2.5-flash\n"
     ]
    }
   ],
   "source": [
    "with gr.Blocks() as app:\n",
    "    with gr.Row():\n",
    "        with gr.Column(scale=1):\n",
    "            gr.Markdown(\"## Elija su modelo de IA preferido.\")\n",
    "            model_selector = gr.Dropdown(\n",
    "                choices=list(models.keys()),\n",
    "                value=\"gemini\",\n",
    "                label=\"Modelo de IA\"\n",
    "            )\n",
    "\n",
    "            selected_chat = gr.Dropdown(choices=[],\n",
    "                                     value=\"\",\n",
    "                                     label=\"Historial de chats\"\n",
    "                                    )\n",
    "            \n",
    "            new_chat_btn =gr.Button(\"➕ Nuevo Chat\", size=\"md\")\n",
    "            \n",
    "            chat_state = gr.State({})\n",
    "            current_chat = gr.State(\"\")\n",
    "\n",
    "        with gr.Column(scale=3):\n",
    "\n",
    "            current_model = gr.State(\"gemini\")\n",
    "\n",
    "            model_selector.change(\n",
    "                fn=lambda model: model,\n",
    "                inputs=model_selector,\n",
    "                outputs=current_model\n",
    "            )\n",
    "\n",
    "            chatbot = gr.Chatbot(type=\"messages\")\n",
    "\n",
    "            gr.ChatInterface(chat, \n",
    "                             chatbot=chatbot, \n",
    "                             additional_inputs=[current_model, chat_state, current_chat], \n",
    "                             type=\"messages\", \n",
    "                             title=\"Chat con Modelos de IA\"\n",
    "                            )\n",
    "\n",
    "            selected_chat.change(\n",
    "                fn=switch_chat,\n",
    "                inputs=[chat_state, selected_chat],\n",
    "                outputs=chatbot\n",
    "            ).then(\n",
    "                fn= lambda cid: cid,\n",
    "                inputs=selected_chat,\n",
    "                outputs=current_chat\n",
    "            )\n",
    "\n",
    "            new_chat_btn.click(fn=new_chat,\n",
    "                               inputs=[chat_state],\n",
    "                               outputs=[chat_state, current_chat, selected_chat, chatbot])\n",
    "\n",
    "            chatbot.change(\n",
    "                fn=save_message,\n",
    "                inputs=[chat_state, current_chat, chatbot],\n",
    "                outputs=chat_state\n",
    "            )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "app.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
